{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Practice]_08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1WhFyJFlODL9qUwlIgbBDpby9x7btRx8u",
      "authorship_tag": "ABX9TyNdLccXe38leXMJTjET22jw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubhranshu-Malhotra/Tensorflow-Developer-ZTM/blob/main/%5BPractice%5D_08_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNO5yhNxBSNh"
      },
      "source": [
        "# Natural Language Processing Basics in TensorFlow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr1cop73Bgdn"
      },
      "source": [
        "## Get helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeCJn9FTBbjZ",
        "outputId": "afc3dec3-9109-4fa0-fab5-cbb9b99ff699"
      },
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-31 10:44:19--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-31 10:44:19 (64.5 MB/s) - ‘helper_functions.py’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVvFggGCBheO"
      },
      "source": [
        "# Import helper functions\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLhkFyOmBnMX"
      },
      "source": [
        "## Download a text dataset\n",
        "\n",
        "We'll be using the [Real or Not?](https://www.kaggle.com/c/nlp-getting-started/data) datset from Kaggle which contains text-based Tweets about natural disasters. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VytMH-aDCMYs",
        "outputId": "e6074b88-60b1-4c76-b9ed-a312fa9b4d3b"
      },
      "source": [
        "# Download data (same as from Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-31 10:47:51--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 172.217.203.128, 172.253.123.128, 142.250.98.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|172.217.203.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip’\n",
            "\n",
            "\rnlp_getting_started   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.006s  \n",
            "\n",
            "2021-05-31 10:47:52 (103 MB/s) - ‘nlp_getting_started.zip’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxVgb_HJCXb2"
      },
      "source": [
        "`nlp_getting_started.zip` contains the following 3 `.csv` files:\n",
        "* `sample_submission.csv` - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n",
        "* `train.csv` - training samples of real and not real diaster Tweets.\n",
        "* `test.csv` - testing samples of real and not real diaster Tweets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De0TyJTaChZK"
      },
      "source": [
        "## Visualize text dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fDoe4EiNm6b"
      },
      "source": [
        "# Read the data\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "95D6Y24oOLda",
        "outputId": "b394d616-7e42-4059-f8ae-4045454a19f3"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JleL7oFxOPk_",
        "outputId": "c0f7d97b-6f3a-437a-e86b-8b727149d3b5"
      },
      "source": [
        "train_df['text'][0]"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkJIS5kwOUp0"
      },
      "source": [
        "train_df_shuffled = train_df.sample(frac = 1, random_state = 42)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "NFKXEdRqOvwx",
        "outputId": "f000e899-aa25-48cd-85c8-d7ad06e627eb"
      },
      "source": [
        "train_df_shuffled.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "zj61FEp2OzkH",
        "outputId": "948d7245-0cf2-4f30-ba66-9e4ffad9cf4a"
      },
      "source": [
        "# Visualize the test data\n",
        "test_df.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqe-2HE9O7_0",
        "outputId": "cb235567-6e05-4cda-d75e-35134a6dfbab"
      },
      "source": [
        "# How many examples of each class\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPU6rp5-PF1P",
        "outputId": "f3bdcad8-1b0f-48ac-a57c-563ad7d3290f"
      },
      "source": [
        "# Total samples\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "zkg-RFveQRQV",
        "outputId": "90f92b75-4bbf-4376-87a1-cb8cba39d702"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword  ...                                               text target\n",
              "0         1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1         4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2         5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3         6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4         7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "...     ...     ...  ...                                                ...    ...\n",
              "7608  10869     NaN  ...  Two giant cranes holding a bridge collapse int...      1\n",
              "7609  10870     NaN  ...  @aria_ahrary @TheTawniest The out of control w...      1\n",
              "7610  10871     NaN  ...  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...      1\n",
              "7611  10872     NaN  ...  Police investigating after an e-bike collided ...      1\n",
              "7612  10873     NaN  ...  The Latest: More Homes Razed by Northern Calif...      1\n",
              "\n",
              "[7613 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2pzqmepP1Vp",
        "outputId": "8eb43e31-20a7-4afc-d374-fee7bb8ddf8f"
      },
      "source": [
        "# Visualize some random training sample\n",
        "import random\n",
        "for i in range(10):\n",
        "  random_index = random.choice(range(0,len(train_df_shuffled)))\n",
        "  target = train_df.iloc[random_index].target\n",
        "  text = train_df.iloc[random_index].text\n",
        "  print(f\"Index: {random_index}\")\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index: 6077\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Sinkhole on west side damaging cars via @WEWS http://t.co/S7grbZNwlr\n",
            "\n",
            "---\n",
            "\n",
            "Index: 645\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@Shayoly yes I love it\n",
            "\n",
            "---\n",
            "\n",
            "Index: 2523\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "yeah 1:57  |  Lamb Of God - Rock Am Ring 2015 - Intro+Desolation HD https://t.co/lEM5Z1NFk3 via @YouTube\n",
            "\n",
            "---\n",
            "\n",
            "Index: 7363\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "IJ: Texas Seeks Comment on Rules for Changes to Windstorm Insurer http://t.co/h132iuL7MU\n",
            "\n",
            "---\n",
            "\n",
            "Index: 4296\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@JYHeffect my good you stay in NY??? ?\n",
            "\n",
            "---\n",
            "\n",
            "Index: 6689\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "THIS IS RELAXING! #thunder #SoothMySlumber #WATERMELOANN #populardemand w/ @Soak... (Vine by @thewebbeffect19) https://t.co/F0QIRS5lJA\n",
            "\n",
            "---\n",
            "\n",
            "Index: 7490\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "GOP debate drinking game. For anyone looking for a bit of fun while watching this train wreck. http://t.co/W3Rga0nkOm http://t.co/0TZsQe8ESD\n",
            "\n",
            "---\n",
            "\n",
            "Index: 3605\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Tell me why or why not\n",
            "to adopt in this way\n",
            "maybe I overlooked something\n",
            "fatal for me\n",
            "?whyor why not?\n",
            "\n",
            "---\n",
            "\n",
            "Index: 5867\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Greedy bastards @Fullscreen way to ruin creativity.  CENSORSHIP ON YOUTUBE: https://t.co/nMtlpO4B58\n",
            "\n",
            "---\n",
            "\n",
            "Index: 3944\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Flood Advisory issued August 05 at 7:10PM CDT until August 05 at 8:00PM CDT by NWS: ...THE URBAN AND ... http://t.co/SeMw5cQ7Dg #weather\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4QKAr8LQW69",
        "outputId": "b3f5da67-e0c0-4734-ca5c-69297556c7a0"
      },
      "source": [
        "len(train_df_shuffled)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AnvbUhYQXaw"
      },
      "source": [
        "### Split data into training and validation sets\n",
        "\n",
        "Since the test set has no labels and we need a way to evalaute our trained models, we'll split off some of the training data and create a validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnuWqrCdSSK5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhSJ12gZSkv3"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_df_shuffled['text'].to_numpy(),\n",
        "                                                  train_df_shuffled['target'].to_numpy(),\n",
        "                                                  test_size = 0.1,\n",
        "                                                  random_state = 42)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cXFmWSnS9hA",
        "outputId": "09af1e52-8df2-4655-8b0c-3ee77f660d5e"
      },
      "source": [
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIYL1An0TMvR",
        "outputId": "eb716743-ba50-469f-8d81-a161235ba0d8"
      },
      "source": [
        "len(train_df_shuffled)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfdYlMAWTQ2e",
        "outputId": "f1622557-facb-420b-9508-6a31fed01feb"
      },
      "source": [
        "len(X_train) + len(X_val)"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jRXZQBcTTyL",
        "outputId": "8f0ce639-bcbd-4bed-ffbe-bf411ebf3a58"
      },
      "source": [
        "# Check the first 10 samples\n",
        "X_train[:10], y_train[:10]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm0EkMh-Ta75",
        "outputId": "62fbf781-13a6-4fe2-e103-b460977f095c"
      },
      "source": [
        "X_val[:10], y_val[:10]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['DFR EP016 Monthly Meltdown - On Dnbheaven 2015.08.06 http://t.co/EjKRf8N8A8 #Drum and Bass #heavy #nasty http://t.co/SPHWE6wFI5',\n",
              "        'FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday',\n",
              "        'Gunmen kill four in El Salvador bus attack: Suspected Salvadoran gang members killed four people and wounded s... http://t.co/CNtwB6ScZj',\n",
              "        '@camilacabello97 Internally and externally screaming',\n",
              "        'Radiation emergency #preparedness starts with knowing to: get inside stay inside and stay tuned http://t.co/RFFPqBAz2F via @CDCgov',\n",
              "        'Investigators rule catastrophic structural failure resulted in 2014 Virg.. Related Articles: http://t.co/Cy1LFeNyV8',\n",
              "        'How the West was burned: Thousands of wildfires ablaze in #California alone http://t.co/iCSjGZ9tE1 #climate #energy http://t.co/9FxmN0l0Bd',\n",
              "        \"Map: Typhoon Soudelor's predicted path as it approaches Taiwan; expected to make landfall over southern China by S\\x89Û_ http://t.co/JDVSGVhlIs\",\n",
              "        '\\x89Ûª93 blasts accused Yeda Yakub dies in Karachi of heart attack http://t.co/mfKqyxd8XG #Mumbai',\n",
              "        'My ears are bleeding  https://t.co/k5KnNwugwT'], dtype=object),\n",
              " array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWVAW9BKTcbZ"
      },
      "source": [
        "## Converting text into numbers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dAMvm40eB2T"
      },
      "source": [
        "### Method 1: Text Vecorization (Tokenization) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g76iDY78eFEW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters [FOR LEARNING PURPOSE]\n",
        "# Automaticalls adds <OOV> token for unknown words\n",
        "test_vectorizer = TextVectorization(max_tokens=None, # num of words in vocabulary\n",
        "                                    standardize = \"lower_and_strip_punctuation\",\n",
        "                                    split = 'whitespace',\n",
        "                                    ngrams = None,\n",
        "                                    output_mode = 'int',\n",
        "                                    output_sequence_length = None,\n",
        "                                    pad_to_max_tokens = True\n",
        "                                    )\n"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caSQvb20jpru",
        "outputId": "58d96183-f10c-418b-81e1-c9f302f23029"
      },
      "source": [
        "len(X_train[0].split())"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaIgQmE9h1rQ",
        "outputId": "ea958bc3-99d4-4e01-e3d8-85ec37b13f85"
      },
      "source": [
        "# Find the average number of tokes (word) in the training tweets\n",
        "AVERAGE_LEN = round(sum([len(i.split()) for i in X_train])/len(X_train))\n",
        "AVERAGE_LEN"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJdQ9X35j9k-"
      },
      "source": [
        "# Set up text vectoriation variables\n",
        "MAX_VOCAB_LEN = 10000\n",
        "MAX_LEN = AVERAGE_LEN"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYwNKS3Wkisb"
      },
      "source": [
        "text_vectorizer = TextVectorization(max_tokens= MAX_VOCAB_LEN,\n",
        "                                    output_mode = 'int',\n",
        "                                    output_sequence_length = MAX_LEN)"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLLDReI3kv2Q"
      },
      "source": [
        "# Fit the text vectorizer to the training set\n",
        "text_vectorizer.adapt(X_train)"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfrHYjHrlUGt",
        "outputId": "6ff8ef5e-ca72-4c44-c930-4b0c30fadf16"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG4DWLTPlg6P",
        "outputId": "6927ad06-50bd-4c82-b682-aaa71c93ffd5"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentences = ['We had a 6.5 earthquake yesterday.', 'We will go for a picnic tomorrow.']\n",
        "text_vectorizer(sample_sentences)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 15), dtype=int64, numpy=\n",
              "array([[  46,   94,    3,    1,  290, 1730,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0],\n",
              "       [  46,   38,  112,   10,    3,    1,  665,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcJf6vp6l0cH"
      },
      "source": [
        "1 represents the \\<OOV> token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3Aly4RDm4jO",
        "outputId": "01cdc073-bb1a-4256-81b5-c43b2bedf8f3"
      },
      "source": [
        "# Choose a random sentence from training dataset and tokenize it\n",
        "random_sentence = random.choice(X_train)\n",
        "print(f'Original text:\\n {random_sentence},\\\n",
        "      \\n \\n Vectorized version:\\n {text_vectorizer([random_sentence])}')"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " August 5 1620 one hundred-odd pilgrims from England and Holland set sail for the New World. They were unimpressed. http://t.co/pW5DSt9ROz,      \n",
            " \n",
            " Vectorized version:\n",
            " [[ 407  180 4185   61    1 9776   20 2126    7 2953  284 4694   10    2\n",
            "    50]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUTNt4PMpls7",
        "outputId": "b88f4862-d1fa-4c52-ab5a-34cd0a2d355b"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in the vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words in vocab: {top_5_words}\")\n",
        "print(f\"5 least common words in vocab: {bottom_5_words}\")"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in the vocab: 10000\n",
            "5 most common words in vocab: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words in vocab: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc8O0ESYqmfQ"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "* `input_dim` - The size of the vocabulary (e.g. `len(text_vectorizer.get_vocabulary()`).\n",
        "* `output_dim` - The size of the output embedding vector, for example, a value of `100` outputs a  feature vector of size 100 for each word.\n",
        "* `embeddings_initializer` - How to initialize the embeddings matrix, default is `\"uniform\"` which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "* `input_length` - Length of sequences being passed to embedding layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRsk38o7rNCB",
        "outputId": "565f669b-a1c9-4c19-e094-4302561a6120"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim = MAX_VOCAB_LEN,\n",
        "                             output_dim = 128,\n",
        "                             input_length = MAX_LEN)\n",
        "embedding"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f6bc2e79a10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16mEIu29rp42",
        "outputId": "82888626-eb29-45ec-8593-ab84bb99b36e"
      },
      "source": [
        "# Get a random sentence from training set and pass through embedding layer\n",
        "random_sentence = random.choice(X_train)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence])) \n",
        "# Right now the representation is random but Will be trained during training to represent sentences better\n",
        "sample_embed"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            "Pizza and beer in a tornado in Austin. Windy af right now      \n",
            "\n",
            "Embedded version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[-0.02710241, -0.03940117,  0.03322748, ...,  0.0138473 ,\n",
              "          0.03265047,  0.01615313],\n",
              "        [-0.01768593, -0.03693328,  0.04749235, ...,  0.00018506,\n",
              "          0.04619315,  0.01932073],\n",
              "        [ 0.02174259,  0.02616348, -0.0263305 , ...,  0.00875334,\n",
              "          0.01121379, -0.01064295],\n",
              "        ...,\n",
              "        [-0.00860177,  0.002195  ,  0.03046748, ...,  0.03435448,\n",
              "          0.03927282,  0.0424802 ],\n",
              "        [-0.00860177,  0.002195  ,  0.03046748, ...,  0.03435448,\n",
              "          0.03927282,  0.0424802 ],\n",
              "        [-0.00860177,  0.002195  ,  0.03046748, ...,  0.03435448,\n",
              "          0.03927282,  0.0424802 ]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giYilwBetoeH",
        "outputId": "b21cd867-eef6-41d9-f0cd-4e217fe9f01c"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([-0.02710241, -0.03940117,  0.03322748, -0.00197525,  0.00418018,\n",
              "         0.04109621, -0.02172433,  0.01911299,  0.0421909 ,  0.00292374,\n",
              "         0.04406803,  0.00344727,  0.02057833, -0.03448272,  0.00714367,\n",
              "         0.00817432, -0.0196963 ,  0.01053535,  0.01997207, -0.00708705,\n",
              "        -0.04668406, -0.03231076, -0.03317335, -0.04334083,  0.00664838,\n",
              "         0.0403544 , -0.01658643,  0.02587331,  0.01126189,  0.02330388,\n",
              "        -0.02133   ,  0.04508654,  0.00030184,  0.00131034, -0.04789979,\n",
              "        -0.03526946, -0.02147988,  0.03097541,  0.01002539, -0.04063845,\n",
              "        -0.04782208,  0.02623738, -0.02821236, -0.0155818 , -0.01514643,\n",
              "         0.00480328,  0.03072102, -0.0137635 ,  0.04529699,  0.03947565,\n",
              "        -0.03592378,  0.02366508, -0.01812452,  0.02854873,  0.04662044,\n",
              "        -0.00254776, -0.04935285,  0.02769354,  0.03076423, -0.01861133,\n",
              "         0.00797483, -0.00886854, -0.0141388 ,  0.04940102, -0.02850964,\n",
              "         0.00981591,  0.03004484, -0.02509387, -0.04614793, -0.04280661,\n",
              "         0.04823586,  0.00028353, -0.03522535, -0.02054086,  0.04767728,\n",
              "        -0.01527977, -0.01369575, -0.03915043, -0.02881616,  0.02830886,\n",
              "         0.02435311, -0.00850264, -0.01964475,  0.01716949, -0.02009902,\n",
              "         0.02120992, -0.03925798, -0.00466485,  0.0085154 ,  0.02559212,\n",
              "        -0.04751114, -0.0036539 ,  0.0125497 ,  0.03512052,  0.01097595,\n",
              "        -0.04338276, -0.0163602 , -0.03176328, -0.0374933 , -0.01692893,\n",
              "         0.0413946 , -0.0165537 ,  0.03172674, -0.00326069, -0.02566776,\n",
              "        -0.02427414,  0.00994594, -0.02571244,  0.02939734, -0.01204187,\n",
              "         0.03300779, -0.00514879, -0.04929945, -0.025255  , -0.00908303,\n",
              "        -0.00454294, -0.02338704, -0.00889859,  0.04440883, -0.04009681,\n",
              "        -0.03892135, -0.01195272, -0.00800058, -0.01980774, -0.03577691,\n",
              "         0.0138473 ,  0.03265047,  0.01615313], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'Pizza and beer in a tornado in Austin. Windy af right now')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93GJzuHBs2qj"
      },
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "we'll be building the following:\n",
        "* **Model 0**: Naive Bayes (baseline) \n",
        "* **Model 1**: Feed-forward neural network (dense model)\n",
        "* **Model 2**: LSTM model\n",
        "* **Model 3**: GRU model\n",
        "* **Model 4**: Bidirectional-LSTM model\n",
        "* **Model 5**: 1D Convolutional Neural Network\n",
        "* **Model 6**: TensorFlow Hub Pretrained Feature Extractor\n",
        "* **Model 7**: Same as model 6 with 10% of training data\n",
        "\n",
        "\n",
        "Each experiment will go through the following steps:\n",
        "* Construct the model\n",
        "* Train the model\n",
        "* Make predictions with the model\n",
        "* Track prediction evaluation metrics for later comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UjzHO6KuplX"
      },
      "source": [
        "### Model 0: Getting a baseline [Naive Bayes]\n",
        "\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon.  \n",
        "  \n",
        "Model 0 is the simplest to acquire a baseline which we'll expect each other of the other deeper models to beat.  \n",
        "\n",
        "\n",
        "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the [Multinomial Naive Bayes algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). This was chosen via referring to the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8g9-vCYv3Tg",
        "outputId": "4da809b9-067d-4172-a42f-7985cbaeb243"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X_train, y_train)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu_DzaVmxT8w",
        "outputId": "ae3044c4-480c-4816-aacb-91d9b6ef9220"
      },
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(X_val, y_val)\n",
        "print(f\"Our baseline model achieves the accuracy of: {baseline_score*100:0.2f}%\")"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline model achieves the accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5JXzEQ1xhI7",
        "outputId": "bc42dfa2-970a-472f-8fd8-fd7646997f83"
      },
      "source": [
        "# Make predictions \n",
        "baseline_preds = model_0.predict(X_val)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OFWyciDy2o5"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh_CTNncx8MI"
      },
      "source": [
        "# add to helper functions\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, accuracy_score\n",
        "def get_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "\n",
        "  metrics = {}\n",
        "  metrics['accuracy'] = 100 * accuracy_score(y_true, y_pred)\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  metrics['precision'], metrics['recall'], metrics['f1_score'], _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "  return metrics"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDQAACwwyx35",
        "outputId": "432e07c1-0e12-4489-e21e-61ffd9a94793"
      },
      "source": [
        "baseline_results = get_results(y_val, baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1_score': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZqH3Gv60w44"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}