{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[Practice]_08_introduction_to_nlp_in_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1WhFyJFlODL9qUwlIgbBDpby9x7btRx8u",
      "authorship_tag": "ABX9TyMm2BbdyJ4TxPAqruQ0NCU3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shubhranshu-Malhotra/Tensorflow-Developer-ZTM/blob/main/%5BPractice%5D_08_introduction_to_nlp_in_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNO5yhNxBSNh"
      },
      "source": [
        "# Natural Language Processing Basics in TensorFlow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr1cop73Bgdn"
      },
      "source": [
        "## Get helper functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeCJn9FTBbjZ",
        "outputId": "54f16840-737b-46da-a8f8-8977eae6f31c"
      },
      "source": [
        "# Download helper functions script\n",
        "!wget https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py"
      ],
      "execution_count": 203,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-31 16:29:05--  https://raw.githubusercontent.com/mrdbourke/tensorflow-deep-learning/main/extras/helper_functions.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10246 (10K) [text/plain]\n",
            "Saving to: ‘helper_functions.py.1’\n",
            "\n",
            "\rhelper_functions.py   0%[                    ]       0  --.-KB/s               \rhelper_functions.py 100%[===================>]  10.01K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-31 16:29:05 (88.6 MB/s) - ‘helper_functions.py.1’ saved [10246/10246]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVvFggGCBheO"
      },
      "source": [
        "# Import helper functions\n",
        "from helper_functions import unzip_data, create_tensorboard_callback, plot_loss_curves, compare_historys"
      ],
      "execution_count": 204,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLhkFyOmBnMX"
      },
      "source": [
        "## Download a text dataset\n",
        "\n",
        "We'll be using the [Real or Not?](https://www.kaggle.com/c/nlp-getting-started/data) datset from Kaggle which contains text-based Tweets about natural disasters. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VytMH-aDCMYs",
        "outputId": "0a4cd8f6-6bad-4456-b3dd-2cdd3baf03f5"
      },
      "source": [
        "# Download data (same as from Kaggle)\n",
        "!wget \"https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\"\n",
        "\n",
        "# Unzip data\n",
        "unzip_data(\"nlp_getting_started.zip\")"
      ],
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-31 16:29:06--  https://storage.googleapis.com/ztm_tf_course/nlp_getting_started.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 74.125.26.128, 172.217.193.128, 172.217.204.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|74.125.26.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 607343 (593K) [application/zip]\n",
            "Saving to: ‘nlp_getting_started.zip.1’\n",
            "\n",
            "\r          nlp_getti   0%[                    ]       0  --.-KB/s               \rnlp_getting_started 100%[===================>] 593.11K  --.-KB/s    in 0.005s  \n",
            "\n",
            "2021-05-31 16:29:06 (124 MB/s) - ‘nlp_getting_started.zip.1’ saved [607343/607343]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxVgb_HJCXb2"
      },
      "source": [
        "`nlp_getting_started.zip` contains the following 3 `.csv` files:\n",
        "* `sample_submission.csv` - an example of the file you'd submit to the Kaggle competition of your model's predictions.\n",
        "* `train.csv` - training samples of real and not real diaster Tweets.\n",
        "* `test.csv` - testing samples of real and not real diaster Tweets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "De0TyJTaChZK"
      },
      "source": [
        "## Visualize text dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4fDoe4EiNm6b"
      },
      "source": [
        "# Read the data\n",
        "import pandas as pd\n",
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 206,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "95D6Y24oOLda",
        "outputId": "6e58d59e-7dae-4dd8-b6a7-2640ba0503e6"
      },
      "source": [
        "train_df.head()"
      ],
      "execution_count": 207,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword  ...                                               text target\n",
              "0   1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1   4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2   5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3   6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4   7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 207
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JleL7oFxOPk_",
        "outputId": "bd88da30-703b-4650-bb37-0ba0f11e928e"
      },
      "source": [
        "train_df['text'][0]"
      ],
      "execution_count": 208,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Our Deeds are the Reason of this #earthquake May ALLAH Forgive us all'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 208
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkJIS5kwOUp0"
      },
      "source": [
        "train_df_shuffled = train_df.sample(frac = 1, random_state = 42)"
      ],
      "execution_count": 209,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "NFKXEdRqOvwx",
        "outputId": "db1cd4db-34ae-47c2-f768-5a52d3284bbc"
      },
      "source": [
        "train_df_shuffled.head()"
      ],
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2644</th>\n",
              "      <td>3796</td>\n",
              "      <td>destruction</td>\n",
              "      <td>NaN</td>\n",
              "      <td>So you have a new weapon that can cause un-ima...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2227</th>\n",
              "      <td>3185</td>\n",
              "      <td>deluge</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The f$&amp;amp;@ing things I do for #GISHWHES Just...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5448</th>\n",
              "      <td>7769</td>\n",
              "      <td>police</td>\n",
              "      <td>UK</td>\n",
              "      <td>DT @georgegalloway: RT @Galloway4Mayor: ÛÏThe...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>191</td>\n",
              "      <td>aftershock</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Aftershock back to school kick off was great. ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6845</th>\n",
              "      <td>9810</td>\n",
              "      <td>trauma</td>\n",
              "      <td>Montgomery County, MD</td>\n",
              "      <td>in response to trauma Children of Addicts deve...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ... target\n",
              "2644  3796  ...      1\n",
              "2227  3185  ...      0\n",
              "5448  7769  ...      1\n",
              "132    191  ...      0\n",
              "6845  9810  ...      0\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 210
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "id": "zj61FEp2OzkH",
        "outputId": "7288ed9a-2a75-496a-c403-f60404ca0164"
      },
      "source": [
        "# Visualize the test data\n",
        "test_df.head()"
      ],
      "execution_count": 211,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just happened a terrible car crash</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Heard about #earthquake is different cities, s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>there is a forest fire at spot pond, geese are...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Apocalypse lighting. #Spokane #wildfires</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>11</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Typhoon Soudelor kills 28 in China and Taiwan</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id keyword location                                               text\n",
              "0   0     NaN      NaN                 Just happened a terrible car crash\n",
              "1   2     NaN      NaN  Heard about #earthquake is different cities, s...\n",
              "2   3     NaN      NaN  there is a forest fire at spot pond, geese are...\n",
              "3   9     NaN      NaN           Apocalypse lighting. #Spokane #wildfires\n",
              "4  11     NaN      NaN      Typhoon Soudelor kills 28 in China and Taiwan"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 211
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqe-2HE9O7_0",
        "outputId": "d5115c8d-4a58-4024-f0c5-9b369526a2b0"
      },
      "source": [
        "# How many examples of each class\n",
        "train_df.target.value_counts()"
      ],
      "execution_count": 212,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hPU6rp5-PF1P",
        "outputId": "f6def49e-2008-4249-86e2-6fbfd2efee01"
      },
      "source": [
        "# Total samples\n",
        "len(train_df), len(test_df)"
      ],
      "execution_count": 213,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 3263)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 213
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "id": "zkg-RFveQRQV",
        "outputId": "08b58a86-b46e-4fa5-a588-704130e7bec4"
      },
      "source": [
        "train_df"
      ],
      "execution_count": 214,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>All residents asked to 'shelter in place' are ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7608</th>\n",
              "      <td>10869</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two giant cranes holding a bridge collapse int...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7609</th>\n",
              "      <td>10870</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>@aria_ahrary @TheTawniest The out of control w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7610</th>\n",
              "      <td>10871</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7611</th>\n",
              "      <td>10872</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Police investigating after an e-bike collided ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7612</th>\n",
              "      <td>10873</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The Latest: More Homes Razed by Northern Calif...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7613 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         id keyword  ...                                               text target\n",
              "0         1     NaN  ...  Our Deeds are the Reason of this #earthquake M...      1\n",
              "1         4     NaN  ...             Forest fire near La Ronge Sask. Canada      1\n",
              "2         5     NaN  ...  All residents asked to 'shelter in place' are ...      1\n",
              "3         6     NaN  ...  13,000 people receive #wildfires evacuation or...      1\n",
              "4         7     NaN  ...  Just got sent this photo from Ruby #Alaska as ...      1\n",
              "...     ...     ...  ...                                                ...    ...\n",
              "7608  10869     NaN  ...  Two giant cranes holding a bridge collapse int...      1\n",
              "7609  10870     NaN  ...  @aria_ahrary @TheTawniest The out of control w...      1\n",
              "7610  10871     NaN  ...  M1.94 [01:04 UTC]?5km S of Volcano Hawaii. htt...      1\n",
              "7611  10872     NaN  ...  Police investigating after an e-bike collided ...      1\n",
              "7612  10873     NaN  ...  The Latest: More Homes Razed by Northern Calif...      1\n",
              "\n",
              "[7613 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 214
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w2pzqmepP1Vp",
        "outputId": "d0b783da-5c17-4604-8941-c3fa1dd59f1e"
      },
      "source": [
        "# Visualize some random training sample\n",
        "import random\n",
        "for i in range(10):\n",
        "  random_index = random.choice(range(0,len(train_df_shuffled)))\n",
        "  target = train_df.iloc[random_index].target\n",
        "  text = train_df.iloc[random_index].text\n",
        "  print(f\"Index: {random_index}\")\n",
        "  print(f\"Target: {target}\", \"(real disaster)\" if target > 0 else \"(not real disaster)\")\n",
        "  print(f\"Text:\\n{text}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": 215,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index: 3176\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Good tips! Does your family have an emergency plan?  ... http://t.co/r5BgVLqPJt http://t.co/MEHWKZwtXD\n",
            "\n",
            "---\n",
            "\n",
            "Index: 1397\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Warfighting Robots Could Reduce Civilian Casualties So Calling for a... http://t.co/9DVU1RidZ3\n",
            "\n",
            "---\n",
            "\n",
            "Index: 3481\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "A Time-Lapse Map of Every Nuclear Explosion Since 1945 - by Isao Hashimoto #War #atomicbomb \n",
            "https://t.co/V0t8H4Iecc\n",
            "\n",
            "---\n",
            "\n",
            "Index: 2869\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "#DroughtMonitor: Moderate or worse #drought ? to ~27% of contig USA; affects ~80M people. http://t.co/YBE9JQoznR http://t.co/328SzflEtZ\n",
            "\n",
            "---\n",
            "\n",
            "Index: 7092\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "@abcnews UK scandal of 2009 caused major upheaval to Parliamentary expenses with subsequent sackings and prison. What are we waiting for?\n",
            "\n",
            "---\n",
            "\n",
            "Index: 5296\n",
            "Target: 1 (real disaster)\n",
            "Text:\n",
            "Families to sue over Legionnaires: More than 40 families affected by the fatal outbreak of Legio... http://t.co/uCBfgIBFOR #MuhamadJabal\n",
            "\n",
            "---\n",
            "\n",
            "Index: 1297\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "You Bitches Walking Around Like Yall Hot Shit &amp; Got Bed Bugs &amp; You Burning ????\n",
            "\n",
            "---\n",
            "\n",
            "Index: 1554\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Please stand up for bees against profit-hungry chemical companies. Keep the ban &amp; #Savebees \n",
            "Sign the petition now:\n",
            "https://t.co/4zsXjGV7iT\n",
            "\n",
            "---\n",
            "\n",
            "Index: 918\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "Black Friday turns Bloody (would rather be shopping) http://t.co/l0pmmtZLwP  #mystery\n",
            "\n",
            "---\n",
            "\n",
            "Index: 3773\n",
            "Target: 0 (not real disaster)\n",
            "Text:\n",
            "It may seem like our fire has been a little burnt out....\n",
            "\n",
            "---\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4QKAr8LQW69",
        "outputId": "b5ac538e-4db0-4779-c0d9-dbf0a71536f0"
      },
      "source": [
        "len(train_df_shuffled)"
      ],
      "execution_count": 216,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 216
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0AnvbUhYQXaw"
      },
      "source": [
        "### Split data into training and validation sets\n",
        "\n",
        "Since the test set has no labels and we need a way to evalaute our trained models, we'll split off some of the training data and create a validation set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnuWqrCdSSK5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhSJ12gZSkv3"
      },
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_df_shuffled['text'].to_numpy(),\n",
        "                                                  train_df_shuffled['target'].to_numpy(),\n",
        "                                                  test_size = 0.1,\n",
        "                                                  random_state = 42)"
      ],
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6cXFmWSnS9hA",
        "outputId": "df4d2096-d24e-4638-b749-ba8740e74956"
      },
      "source": [
        "len(X_train), len(y_train), len(X_val), len(y_val)"
      ],
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6851, 6851, 762, 762)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cIYL1An0TMvR",
        "outputId": "e7f5e696-6421-4499-ff99-13efac8d28d5"
      },
      "source": [
        "len(train_df_shuffled)"
      ],
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 220
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfdYlMAWTQ2e",
        "outputId": "29c3c1c0-4439-4f5d-ea61-2cd51778e9b2"
      },
      "source": [
        "len(X_train) + len(X_val)"
      ],
      "execution_count": 221,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7613"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 221
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1jRXZQBcTTyL",
        "outputId": "ddfae64a-1bab-4083-86f0-a60b7e627ef5"
      },
      "source": [
        "# Check the first 10 samples\n",
        "X_train[:10], y_train[:10]"
      ],
      "execution_count": 222,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['@mogacola @zamtriossu i screamed after hitting tweet',\n",
              "        'Imagine getting flattened by Kurt Zouma',\n",
              "        '@Gurmeetramrahim #MSGDoing111WelfareWorks Green S welfare force ke appx 65000 members har time disaster victim ki help ke liye tyar hai....',\n",
              "        \"@shakjn @C7 @Magnums im shaking in fear he's gonna hack the planet\",\n",
              "        'Somehow find you and I collide http://t.co/Ee8RpOahPk',\n",
              "        '@EvaHanderek @MarleyKnysh great times until the bus driver held us hostage in the mall parking lot lmfao',\n",
              "        'destroy the free fandom honestly',\n",
              "        'Weapons stolen from National Guard Armory in New Albany still missing #Gunsense http://t.co/lKNU8902JE',\n",
              "        '@wfaaweather Pete when will the heat wave pass? Is it really going to be mid month? Frisco Boy Scouts have a canoe trip in Okla.',\n",
              "        'Patient-reported outcomes in long-term survivors of metastatic colorectal cancer - British Journal of Surgery http://t.co/5Yl4DC1Tqt'],\n",
              "       dtype=object), array([0, 0, 1, 0, 0, 1, 1, 0, 1, 1]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 222
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qm0EkMh-Ta75",
        "outputId": "0175dd3d-53c5-4ef3-8512-31650176dbcb"
      },
      "source": [
        "X_val[:10], y_val[:10]"
      ],
      "execution_count": 223,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array(['DFR EP016 Monthly Meltdown - On Dnbheaven 2015.08.06 http://t.co/EjKRf8N8A8 #Drum and Bass #heavy #nasty http://t.co/SPHWE6wFI5',\n",
              "        'FedEx no longer to transport bioterror germs in wake of anthrax lab mishaps http://t.co/qZQc8WWwcN via @usatoday',\n",
              "        'Gunmen kill four in El Salvador bus attack: Suspected Salvadoran gang members killed four people and wounded s... http://t.co/CNtwB6ScZj',\n",
              "        '@camilacabello97 Internally and externally screaming',\n",
              "        'Radiation emergency #preparedness starts with knowing to: get inside stay inside and stay tuned http://t.co/RFFPqBAz2F via @CDCgov',\n",
              "        'Investigators rule catastrophic structural failure resulted in 2014 Virg.. Related Articles: http://t.co/Cy1LFeNyV8',\n",
              "        'How the West was burned: Thousands of wildfires ablaze in #California alone http://t.co/iCSjGZ9tE1 #climate #energy http://t.co/9FxmN0l0Bd',\n",
              "        \"Map: Typhoon Soudelor's predicted path as it approaches Taiwan; expected to make landfall over southern China by S\\x89Û_ http://t.co/JDVSGVhlIs\",\n",
              "        '\\x89Ûª93 blasts accused Yeda Yakub dies in Karachi of heart attack http://t.co/mfKqyxd8XG #Mumbai',\n",
              "        'My ears are bleeding  https://t.co/k5KnNwugwT'], dtype=object),\n",
              " array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fWVAW9BKTcbZ"
      },
      "source": [
        "## Converting text into numbers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dAMvm40eB2T"
      },
      "source": [
        "### Method 1: Text Vecorization (Tokenization) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g76iDY78eFEW"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
        "\n",
        "# Use the default TextVectorization parameters [FOR LEARNING PURPOSE]\n",
        "# Automaticalls adds <OOV> token for unknown words\n",
        "test_vectorizer = TextVectorization(max_tokens=None, # num of words in vocabulary\n",
        "                                    standardize = \"lower_and_strip_punctuation\",\n",
        "                                    split = 'whitespace',\n",
        "                                    ngrams = None,\n",
        "                                    output_mode = 'int',\n",
        "                                    output_sequence_length = None,\n",
        "                                    pad_to_max_tokens = True\n",
        "                                    )\n"
      ],
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "caSQvb20jpru",
        "outputId": "2100389c-dd35-4e56-97c7-169fdd1cca14"
      },
      "source": [
        "len(X_train[0].split())"
      ],
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 225
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OaIgQmE9h1rQ",
        "outputId": "3d45bbd1-30d0-45fc-b03d-8493f1181db2"
      },
      "source": [
        "# Find the average number of tokes (word) in the training tweets\n",
        "AVERAGE_LEN = round(sum([len(i.split()) for i in X_train])/len(X_train))\n",
        "AVERAGE_LEN"
      ],
      "execution_count": 226,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 226
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJdQ9X35j9k-"
      },
      "source": [
        "# Set up text vectoriation variables\n",
        "MAX_VOCAB_LEN = 10000\n",
        "MAX_LEN = AVERAGE_LEN"
      ],
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYwNKS3Wkisb"
      },
      "source": [
        "text_vectorizer = TextVectorization(max_tokens= MAX_VOCAB_LEN,\n",
        "                                    output_mode = 'int',\n",
        "                                    output_sequence_length = MAX_LEN)"
      ],
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLLDReI3kv2Q"
      },
      "source": [
        "# Fit the text vectorizer to the training set\n",
        "text_vectorizer.adapt(X_train)"
      ],
      "execution_count": 229,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfrHYjHrlUGt",
        "outputId": "32641c52-b438-4e90-fdc5-815d85ba3a45"
      },
      "source": [
        "type(X_train)"
      ],
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 230
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cG4DWLTPlg6P",
        "outputId": "c86cba42-bd87-4adc-ac51-70702d559bf9"
      },
      "source": [
        "# Create a sample sentence and tokenize it\n",
        "sample_sentences = ['We had a 6.5 earthquake yesterday.', 'We will go for a picnic tomorrow.']\n",
        "text_vectorizer(sample_sentences)"
      ],
      "execution_count": 231,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 15), dtype=int64, numpy=\n",
              "array([[  46,   94,    3,    1,  290, 1730,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0],\n",
              "       [  46,   38,  112,   10,    3,    1,  665,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 231
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JcJf6vp6l0cH"
      },
      "source": [
        "1 represents the \\<OOV> token"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3Aly4RDm4jO",
        "outputId": "4d008101-8cff-444c-b626-69d90e5c523c"
      },
      "source": [
        "# Choose a random sentence from training dataset and tokenize it\n",
        "random_sentence = random.choice(X_train)\n",
        "print(f'Original text:\\n {random_sentence},\\\n",
        "      \\n \\n Vectorized version:\\n {text_vectorizer([random_sentence])}')"
      ],
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            " I've been meaning to harm you in the best way I see fit??,      \n",
            " \n",
            " Vectorized version:\n",
            " [[ 276   59 5150    5  396   12    4    2  149  147    8   99 3845    0\n",
            "     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUTNt4PMpls7",
        "outputId": "f8a71b83-9e49-4a52-e5d2-f18998b9ed24"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "top_5_words = words_in_vocab[:5] # get the most common words\n",
        "bottom_5_words = words_in_vocab[-5:] # get the least common words\n",
        "print(f\"Number of words in the vocab: {len(words_in_vocab)}\")\n",
        "print(f\"5 most common words in vocab: {top_5_words}\")\n",
        "print(f\"5 least common words in vocab: {bottom_5_words}\")"
      ],
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of words in the vocab: 10000\n",
            "5 most common words in vocab: ['', '[UNK]', 'the', 'a', 'in']\n",
            "5 least common words in vocab: ['pages', 'paeds', 'pads', 'padres', 'paddytomlinson1']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jc8O0ESYqmfQ"
      },
      "source": [
        "### Creating an Embedding using an Embedding Layer\n",
        "\n",
        "The main parameters we're concerned about here are:\n",
        "* `input_dim` - The size of the vocabulary (e.g. `len(text_vectorizer.get_vocabulary()`).\n",
        "* `output_dim` - The size of the output embedding vector, for example, a value of `100` outputs a  feature vector of size 100 for each word.\n",
        "* `embeddings_initializer` - How to initialize the embeddings matrix, default is `\"uniform\"` which randomly initalizes embedding matrix with uniform distribution. This can be changed for using pre-learned embeddings.\n",
        "* `input_length` - Length of sequences being passed to embedding layer.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRsk38o7rNCB",
        "outputId": "5a7bfc39-f29c-4170-b340-f87f3c6896c8"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim = MAX_VOCAB_LEN,\n",
        "                             output_dim = 128,\n",
        "                             input_length = MAX_LEN)\n",
        "embedding"
      ],
      "execution_count": 234,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.layers.embeddings.Embedding at 0x7f6bc2e25f10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 234
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16mEIu29rp42",
        "outputId": "41cd9933-c434-451b-ce03-c5b91bdb658b"
      },
      "source": [
        "# Get a random sentence from training set and pass through embedding layer\n",
        "random_sentence = random.choice(X_train)\n",
        "print(f\"Original text:\\n{random_sentence}\\\n",
        "      \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into numerical representation)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence])) \n",
        "# Right now the representation is random but Will be trained during training to represent sentences better\n",
        "sample_embed"
      ],
      "execution_count": 235,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original text:\n",
            "Hellfire! We donÛªt even want to think about it or mention it so letÛªs not do anything that leads to it #islam!      \n",
            "\n",
            "Embedded version:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.03394032, -0.00414902, -0.00505615, ...,  0.04956752,\n",
              "         -0.0431301 , -0.0019838 ],\n",
              "        [ 0.04411567, -0.03109492, -0.03186083, ...,  0.0035655 ,\n",
              "          0.03253884, -0.04101529],\n",
              "        [ 0.01489315,  0.03877788, -0.02588973, ..., -0.00502955,\n",
              "          0.01819697, -0.01448749],\n",
              "        ...,\n",
              "        [ 0.04902091,  0.01188564,  0.00787157, ..., -0.03334521,\n",
              "          0.01139297,  0.01662776],\n",
              "        [ 0.03202711,  0.03683296,  0.02506775, ..., -0.01905179,\n",
              "         -0.02268473,  0.03244457],\n",
              "        [-0.03981008,  0.04948455,  0.03463351, ..., -0.00662028,\n",
              "          0.01352016, -0.02012481]]], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 235
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "giYilwBetoeH",
        "outputId": "9aec1b9a-cde2-4c12-fa67-59caea9dd92d"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "execution_count": 236,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.03394032, -0.00414902, -0.00505615,  0.01295565, -0.02924624,\n",
              "        -0.01773889, -0.02468914, -0.00222046, -0.04161549,  0.04947766,\n",
              "         0.0182218 ,  0.02679162, -0.04718339, -0.04511505,  0.04513779,\n",
              "        -0.01036153, -0.0081498 ,  0.00190473,  0.04820727, -0.00842274,\n",
              "        -0.00233291, -0.03278758,  0.01559044, -0.00754191, -0.01132131,\n",
              "         0.023405  , -0.03292253,  0.03924102,  0.03552529,  0.01706677,\n",
              "         0.04694769,  0.02295091,  0.00053942, -0.02066586, -0.02896285,\n",
              "         0.03332068,  0.02040577,  0.01101758,  0.00572832,  0.0270206 ,\n",
              "        -0.00799593, -0.00488629,  0.01216163,  0.01845653,  0.020383  ,\n",
              "        -0.00632035,  0.03249342,  0.0331453 , -0.02876091,  0.03235031,\n",
              "         0.0044861 , -0.03440344, -0.01962955,  0.03671552, -0.0076311 ,\n",
              "        -0.04391711,  0.03377061, -0.02992722,  0.03416386,  0.03173857,\n",
              "         0.00265987,  0.0492785 ,  0.01538069, -0.00884574, -0.04098377,\n",
              "         0.03995203, -0.02341987,  0.02560821,  0.04390046,  0.04996163,\n",
              "        -0.02143191,  0.04717343, -0.04044599,  0.04533176, -0.00561672,\n",
              "         0.01732333,  0.04561656, -0.02617108,  0.03901542,  0.02607888,\n",
              "         0.01881344,  0.0434065 ,  0.01318613,  0.0070567 , -0.0484771 ,\n",
              "        -0.04748312, -0.01973253, -0.01407031, -0.04743348,  0.00117349,\n",
              "        -0.01348133, -0.04896633,  0.01778421, -0.0209341 ,  0.04099183,\n",
              "        -0.00124812, -0.01629046, -0.00582963,  0.00659662,  0.02143225,\n",
              "         0.04235048, -0.00661826, -0.03357844, -0.03316931,  0.03496386,\n",
              "        -0.00289156,  0.02965813, -0.02726109,  0.01856801,  0.01837612,\n",
              "        -0.0016886 ,  0.01092967,  0.04667218,  0.04135445, -0.04779879,\n",
              "         0.03716998,  0.03681615,  0.00847422, -0.0300392 , -0.032594  ,\n",
              "        -0.04086009, -0.04187878, -0.03774239, -0.01158363, -0.02991292,\n",
              "         0.04956752, -0.0431301 , -0.0019838 ], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " 'Hellfire! We don\\x89Ûªt even want to think about it or mention it so let\\x89Ûªs not do anything that leads to it #islam!')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 236
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "93GJzuHBs2qj"
      },
      "source": [
        "## Modelling a text dataset (running a series of experiments)\n",
        "we'll be building the following:\n",
        "* **Model 0**: Naive Bayes (baseline) \n",
        "* **Model 1**: Feed-forward neural network (dense model)\n",
        "* **Model 2**: LSTM model\n",
        "* **Model 3**: GRU model\n",
        "* **Model 4**: Bidirectional-LSTM model\n",
        "* **Model 5**: 1D Convolutional Neural Network\n",
        "* **Model 6**: TensorFlow Hub Pretrained Feature Extractor\n",
        "* **Model 7**: Same as model 6 with 10% of training data\n",
        "\n",
        "\n",
        "Each experiment will go through the following steps:\n",
        "* Construct the model\n",
        "* Train the model\n",
        "* Make predictions with the model\n",
        "* Track prediction evaluation metrics for later comparison\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6UjzHO6KuplX"
      },
      "source": [
        "### Model 0: Getting a baseline [Naive Bayes]\n",
        "\n",
        "As with all machine learning modelling experiments, it's important to create a baseline model so you've got a benchmark for future experiments to build upon.  \n",
        "  \n",
        "Model 0 is the simplest to acquire a baseline which we'll expect each other of the other deeper models to beat.  \n",
        "\n",
        "\n",
        "To create our baseline, we'll create a Scikit-Learn Pipeline using the TF-IDF (term frequency-inverse document frequency) formula to convert our words to numbers and then model them with the [Multinomial Naive Bayes algorithm](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB). This was chosen via referring to the [Scikit-Learn machine learning map](https://scikit-learn.org/stable/tutorial/machine_learning_map/index.html).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8g9-vCYv3Tg",
        "outputId": "a5112a59-967e-45cf-9fc4-ded82c95a71f"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(X_train, y_train)"
      ],
      "execution_count": 237,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 237
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iu_DzaVmxT8w",
        "outputId": "b092ecce-2e89-47f7-eebc-93a1ae9f776f"
      },
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(X_val, y_val)\n",
        "print(f\"Our baseline model achieves the accuracy of: {baseline_score*100:0.2f}%\")"
      ],
      "execution_count": 238,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Our baseline model achieves the accuracy of: 79.27%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M5JXzEQ1xhI7",
        "outputId": "0e5aa76c-0d02-4586-d291-1892e230d65a"
      },
      "source": [
        "# Make predictions \n",
        "baseline_preds = model_0.predict(X_val)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": 239,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 239
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OFWyciDy2o5"
      },
      "source": [
        "### Creating an evaluation function for our model experiments\n",
        "\n",
        "* Accuracy\n",
        "* Precision\n",
        "* Recall\n",
        "* F1-score\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mh_CTNncx8MI"
      },
      "source": [
        "# add to helper functions\n",
        "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix, accuracy_score\n",
        "def get_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  -----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted labels in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall, f1-score.\n",
        "  \"\"\"\n",
        "\n",
        "  metrics = {}\n",
        "  metrics['accuracy'] = 100 * accuracy_score(y_true, y_pred)\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" average\n",
        "  metrics['precision'], metrics['recall'], metrics['f1_score'], _ = precision_recall_fscore_support(y_true, y_pred, average='weighted')\n",
        "  return metrics"
      ],
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pDQAACwwyx35",
        "outputId": "10fdb171-9b70-4e2e-ca67-bb8b28f62a64"
      },
      "source": [
        "baseline_results = get_results(y_val, baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": 241,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1_score': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 241
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZqH3Gv60w44"
      },
      "source": [
        "### Model 1: A simple dense model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SajoqCoR7AeG"
      },
      "source": [
        "# tensorboard callback\n",
        "from helper_functions import create_tensorboard_callback\n",
        "tensorboard_dir = \"/content/drive/MyDrive/ZTM_tensorflow_developer/tensorboard\""
      ],
      "execution_count": 242,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bjdKXZKq9Fsq"
      },
      "source": [
        "# Build a model using functional api\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string, name = 'input_layer')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)"
      ],
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHBPPPDm9qsb",
        "outputId": "6fea8586-6175-4417-bb5b-48738fb0ade6"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 244,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_4 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 15, 1)             129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3j4FoyBz-AE6"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-WRXDgMc-NDY",
        "outputId": "f264cdf5-f52f-4749-a19f-51e77d2b7f65"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(X_train, y_train,\n",
        "                            epochs = 5,\n",
        "                            validation_data = (X_val, y_val),\n",
        "                            callbacks = [create_tensorboard_callback(dir_name = tensorboard_dir,\n",
        "                                                                     experiment_name = 'nlp_model_1_dense')])"
      ],
      "execution_count": 246,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: /content/drive/MyDrive/ZTM_tensorflow_developer/tensorboard/nlp_model_1_dense/20210531-162909\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 5s 17ms/step - loss: 0.6493 - accuracy: 0.6390 - val_loss: 0.6293 - val_accuracy: 0.6481\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.5971 - accuracy: 0.6894 - val_loss: 0.6244 - val_accuracy: 0.6480\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.5771 - accuracy: 0.6905 - val_loss: 0.6277 - val_accuracy: 0.6482\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.5678 - accuracy: 0.6932 - val_loss: 0.6311 - val_accuracy: 0.6459\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.5637 - accuracy: 0.6918 - val_loss: 0.6313 - val_accuracy: 0.6463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqfBzIYO-lbM",
        "outputId": "5e524c7c-4829-4ac4-d586-608b85fbf782"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(X_val, y_val)"
      ],
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.6313 - accuracy: 0.6463\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.6312629580497742, 0.6462817192077637]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 247
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wanFbjUg-z4x",
        "outputId": "feef668e-8e21-4197-813d-bc2ec0b21fa8"
      },
      "source": [
        "# Make predictions\n",
        "model_1_pred_probs = model_1.predict(X_val)\n",
        "model_1_pred_probs, model_1_pred_probs.shape"
      ],
      "execution_count": 248,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[[0.45258433],\n",
              "         [0.45258433],\n",
              "         [0.45258433],\n",
              "         ...,\n",
              "         [0.03935131],\n",
              "         [0.45258433],\n",
              "         [0.39245868]],\n",
              " \n",
              "        [[0.5742079 ],\n",
              "         [0.38198924],\n",
              "         [0.46945179],\n",
              "         ...,\n",
              "         [0.8217069 ],\n",
              "         [0.45258433],\n",
              "         [0.566287  ]],\n",
              " \n",
              "        [[0.931408  ],\n",
              "         [0.53375846],\n",
              "         [0.5857269 ],\n",
              "         ...,\n",
              "         [0.9689521 ],\n",
              "         [0.5857269 ],\n",
              "         [0.54292756]],\n",
              " \n",
              "        ...,\n",
              " \n",
              "        [[0.5742079 ],\n",
              "         [0.3562048 ],\n",
              "         [0.38198924],\n",
              "         ...,\n",
              "         [0.8217069 ],\n",
              "         [0.45258433],\n",
              "         [0.39245868]],\n",
              " \n",
              "        [[0.0982407 ],\n",
              "         [0.6179534 ],\n",
              "         [0.41631907],\n",
              "         ...,\n",
              "         [0.41414636],\n",
              "         [0.2991696 ],\n",
              "         [0.3486641 ]],\n",
              " \n",
              "        [[0.1770744 ],\n",
              "         [0.14827904],\n",
              "         [0.45884922],\n",
              "         ...,\n",
              "         [0.43125758],\n",
              "         [0.2883792 ],\n",
              "         [0.6129771 ]]], dtype=float32), (762, 15, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 248
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XvrIBzRL_Df5",
        "outputId": "52b4c27a-62d8-4d71-ce37-2b724f09d228"
      },
      "source": [
        "model_1_pred_probs[0]"
      ],
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.45258433],\n",
              "       [0.45258433],\n",
              "       [0.45258433],\n",
              "       [0.18486896],\n",
              "       [0.49349102],\n",
              "       [0.45258433],\n",
              "       [0.45258433],\n",
              "       [0.45258433],\n",
              "       [0.10623497],\n",
              "       [0.4148156 ],\n",
              "       [0.45258433],\n",
              "       [0.95250505],\n",
              "       [0.03935131],\n",
              "       [0.45258433],\n",
              "       [0.39245868]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 249
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZtcuyvG_Ghg"
      },
      "source": [
        "There is something wrong here as we only need one probability for the whole sentence and not probability for each token.  \n",
        "This problem is caused because we didn't use GlobalAveragePooling.  \n",
        "Let's rebuild it, this time adding the GlobalAveragePooling layer.  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9eiyIYGj_VSt"
      },
      "source": [
        "# Build a model using functional api\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape = (1,), dtype = tf.string, name = 'input_layer')\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.GlobalAveragePooling1D()(x)\n",
        "outputs = layers.Dense(1, activation = 'sigmoid')(x)\n",
        "model_1 = tf.keras.Model(inputs, outputs)\n"
      ],
      "execution_count": 269,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JibiFSwS_sQL",
        "outputId": "83b8945d-8bd3-4a4e-de10-0134d401b01a"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 251,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_10\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_4 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_6 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_10 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOc8_9i3Fu2V"
      },
      "source": [
        "# Compile the model\n",
        "model_1.compile(loss = tf.keras.losses.BinaryCrossentropy(),\n",
        "                optimizer = tf.keras.optimizers.Adam(),\n",
        "                metrics = ['accuracy'])"
      ],
      "execution_count": 252,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NYnVwOOgFu3H",
        "outputId": "7194e3fb-e72d-4fd3-8f13-e58d6a5de277"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(X_train, y_train,\n",
        "                            epochs = 5,\n",
        "                            validation_data = (X_val, y_val),\n",
        "                            callbacks = [create_tensorboard_callback(dir_name = tensorboard_dir,\n",
        "                                                                     experiment_name = 'nlp_model_1_dense')])"
      ],
      "execution_count": 253,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving TensorBoard log files to: /content/drive/MyDrive/ZTM_tensorflow_developer/tensorboard/nlp_model_1_dense/20210531-162927\n",
            "Epoch 1/5\n",
            "215/215 [==============================] - 4s 17ms/step - loss: 0.5663 - accuracy: 0.7609 - val_loss: 0.5204 - val_accuracy: 0.7703\n",
            "Epoch 2/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3982 - accuracy: 0.8529 - val_loss: 0.4618 - val_accuracy: 0.7874\n",
            "Epoch 3/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.3169 - accuracy: 0.8787 - val_loss: 0.4500 - val_accuracy: 0.7900\n",
            "Epoch 4/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.2642 - accuracy: 0.9024 - val_loss: 0.4604 - val_accuracy: 0.7979\n",
            "Epoch 5/5\n",
            "215/215 [==============================] - 3s 15ms/step - loss: 0.2243 - accuracy: 0.9184 - val_loss: 0.4664 - val_accuracy: 0.7822\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VmgRgH5TFu3J",
        "outputId": "8b4eefe1-ff8d-4ce4-fef1-930eea9fc9c5"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(X_val, y_val)"
      ],
      "execution_count": 254,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "24/24 [==============================] - 0s 2ms/step - loss: 0.4664 - accuracy: 0.7822\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4663676917552948, 0.7821522355079651]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 254
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IUZXVfnYFwm1",
        "outputId": "b839fad1-a5ef-4176-9c0c-e43ef404f81c"
      },
      "source": [
        "# Make predictions\n",
        "model_1_pred_probs = model_1.predict(X_val)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": 255,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(762, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 255
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8eJWk2nF_8d",
        "outputId": "c9734654-02fc-463b-eecd-e25fee675169"
      },
      "source": [
        "model_1_pred_probs[0]"
      ],
      "execution_count": 256,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.41683644], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 256
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBNcxf1hGBpU",
        "outputId": "169d6c57-4fe8-4d13-ca03-9a625963330a"
      },
      "source": [
        "# look at first 10 predictions\n",
        "model_1_pred_probs[:10]"
      ],
      "execution_count": 257,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.41683644],\n",
              "       [0.7686113 ],\n",
              "       [0.9970106 ],\n",
              "       [0.18166536],\n",
              "       [0.14640331],\n",
              "       [0.9493388 ],\n",
              "       [0.88575554],\n",
              "       [0.9962744 ],\n",
              "       [0.96875775],\n",
              "       [0.32348743]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 257
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FqF3XyIRGPky",
        "outputId": "cca47bea-5da6-42c8-a856-fa714c346e2b"
      },
      "source": [
        "y_val[:10]"
      ],
      "execution_count": 258,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, 1, 1, 1, 1, 1, 1, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 258
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "egbIN0pZGwur"
      },
      "source": [
        "As we can see that our validation labels are in 1 or 0 format we need to convert our model's prediction probabilities to label format too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wm1BJ_Z4G68a"
      },
      "source": [
        "# Convert prediction probabilities to label format\n",
        "# model_1_pred_labels = [0 if i>0.5 else 1 for i in model_1_pred_probs]\n",
        "model_1_pred_labels = tf.squeeze(tf.round(model_1_pred_probs))"
      ],
      "execution_count": 259,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ts68DEfuHQZS",
        "outputId": "d1214394-51c0-42cf-9192-2b5e64eee1dd"
      },
      "source": [
        "model_1_pred_labels[:10]"
      ],
      "execution_count": 260,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([0., 1., 1., 0., 0., 1., 1., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 260
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KjXqdsb2HvVq",
        "outputId": "cb16311d-35d6-4b57-f671-3c82c9b6eb3e"
      },
      "source": [
        "model_1_results = get_results(y_val, model_1_pred_labels)\n",
        "model_1_results"
      ],
      "execution_count": 261,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 78.21522309711287,\n",
              " 'f1_score': 0.7804155135464126,\n",
              " 'precision': 0.7835553063606987,\n",
              " 'recall': 0.7821522309711286}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 261
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJOefW3nKVXb",
        "outputId": "c143dec5-4283-490d-b878-e755994739b3"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": 262,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 79.26509186351706,\n",
              " 'f1_score': 0.7862189758049549,\n",
              " 'precision': 0.8111390004213173,\n",
              " 'recall': 0.7926509186351706}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 262
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pX2CIuoQI0GY",
        "outputId": "1c4f56e3-1759-4c4a-f729-1541ad6854d7"
      },
      "source": [
        "import numpy as np\n",
        "np.array(list(model_1_results.values())) > np.array(list(baseline_results.values()))"
      ],
      "execution_count": 263,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([False, False, False, False])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 263
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Px7kkgGkKc2O"
      },
      "source": [
        "## Visualizing learned embeddings\n",
        "\n",
        "Our first model (`model_1`) contained an embedding layer (`embedding`) which learned a way of representing words as feature vectors by passing over the training data.\n",
        "\n",
        "To further help understand what a text embedding is, let's visualize the embedding our model learned.\n",
        "\n",
        "To do so, let's remind ourselves of the words in our vocabulary.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9X3rSZ1JRv0Y",
        "outputId": "6a63d0d8-ee76-42d1-e383-0d104c06fed1"
      },
      "source": [
        "# Get the vocabulary\n",
        "word_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": 264,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'the', 'a', 'in', 'to', 'of', 'and', 'i', 'is'])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 264
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzOy-xqKYyzX",
        "outputId": "f0b8fc39-29b2-42df-e038-59ff80b70a39"
      },
      "source": [
        "MAX_VOCAB_LEN"
      ],
      "execution_count": 265,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 265
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yw6OYk3dY2Oy",
        "outputId": "eba16ec4-fbab-4eb6-db2a-20b6aa23218d"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": 270,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_layer (InputLayer)     [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization_4 (TextVe (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding_2 (Embedding)      (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d_7 ( (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_11 (Dense)             (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Khyg_kvQY6nH"
      },
      "source": [
        "# Get the weight matrix of embedding layer \n",
        "# (these are the numerical patterns between the text in the training dataset the model has learned)\n",
        "embed_weights = model_1.get_layer('embedding_2').get_weights()[0]"
      ],
      "execution_count": 272,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VsqGNWniZXVV",
        "outputId": "57e73e1e-81fc-4543-8da7-2996e2fa05fd"
      },
      "source": [
        "embed_weights"
      ],
      "execution_count": 273,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.000851  , -0.06826828,  0.0104061 , ..., -0.03496656,\n",
              "        -0.05664244,  0.01203023],\n",
              "       [-0.01925762,  0.0171201 ,  0.01295353, ..., -0.02738079,\n",
              "         0.00070074, -0.07143973],\n",
              "       [-0.01727312, -0.06529462,  0.01217169, ...,  0.01467015,\n",
              "        -0.04821666, -0.04728634],\n",
              "       ...,\n",
              "       [ 0.0090167 ,  0.01473334,  0.01535289, ...,  0.04191733,\n",
              "        -0.04135593,  0.046917  ],\n",
              "       [ 0.03651113,  0.10984478,  0.03795978, ..., -0.07329595,\n",
              "         0.07839   ,  0.12091658],\n",
              "       [ 0.14036895,  0.10980735,  0.12360164, ..., -0.08522652,\n",
              "         0.08948015,  0.09086819]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 273
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g88SPCLAZ5B8",
        "outputId": "83667ece-c721-4b84-b40a-8e7b88a1fe2a"
      },
      "source": [
        "embed_weights.shape"
      ],
      "execution_count": 274,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 274
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yXfcdSjnZ8uj"
      },
      "source": [
        "Now we've got these two objects, we can use the [Embedding Projector tool](http://projector.tensorflow.org/_) to visualize our embedding. \n",
        "\n",
        "To use the Embedding Projector tool, we need two files:\n",
        "* The embedding vectors (same as embedding weights).\n",
        "* The meta data of the embedding vectors (the words they represent - our vocabulary).\n",
        "\n",
        "Right now, we've got of these files as Python objects. To download them to file, we're going to [use the code example available on the TensorFlow word embeddings tutorial page](https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "xWEVZbVMbeUj",
        "outputId": "99fcbd89-4059-4a14-cf18-e9b662253f6e"
      },
      "source": [
        "# Code below is adapted from: https://www.tensorflow.org/tutorials/text/word_embeddings#retrieve_the_trained_word_embeddings_and_save_them_to_disk\n",
        "import io\n",
        "\n",
        "# Create output writers\n",
        "out_v = io.open(\"embedding_vectors.tsv\", \"w\", encoding=\"utf-8\")\n",
        "out_m = io.open(\"embedding_metadata.tsv\", \"w\", encoding=\"utf-8\")\n",
        "\n",
        "# Write embedding vectors and words to file\n",
        "for num, word in enumerate(words_in_vocab):\n",
        "  if num == 0: \n",
        "     continue # skip padding token\n",
        "  vec = embed_weights[num]\n",
        "  out_m.write(word + \"\\n\") # write words to file\n",
        "  out_v.write(\"\\t\".join([str(x) for x in vec]) + \"\\n\") # write corresponding word vector to file\n",
        "out_v.close()\n",
        "out_m.close()\n",
        "\n",
        "# Download files locally to upload to Embedding Projector\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "else:\n",
        "  files.download(\"embedding_vectors.tsv\")\n",
        "  files.download(\"embedding_metadata.tsv\")"
      ],
      "execution_count": 275,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_1a2d5f60-e9fb-4856-abb7-f5ad8c187299\", \"embedding_vectors.tsv\", 15097944)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_4b46989d-2ce4-400b-8c60-fca8849ed4f1\", \"embedding_metadata.tsv\", 80388)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbcrYRcscORE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}